{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  This exercises uses the case.csv, dept.csv, and source.csv files from the san antonio 311 call dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read the case, department, and source data into their own spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the source df\n",
    "source_df = spark.read.csv(\"source.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "#Create the department df\n",
    "dept_df = spark.read.csv(\"dept.csv\", sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "#Create the case df\n",
    "case_df = spark.read.csv(\"case.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- case ---\n",
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 2018-01-01 00:42:00  \n",
      " case_closed_date     | 2018-01-01 00:42:00  \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616000001   \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      " case_due_date        | 2018-01-01 00:42:00  \n",
      " year                 | 2018                 \n",
      "only showing top 1 row\n",
      "\n",
      "--- dept ---\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|       dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "|     311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|               Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "|     Clean and Green|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "|Clean and Green N...|Parks and Recreation|    Parks & Recreation|                YES|\n",
      "|    Code Enforcement|Code Enforcement ...|  DSD/Code Enforcement|                YES|\n",
      "|Code Enforcement ...|Code Enforcement ...|  DSD/Code Enforcement|                YES|\n",
      "|Code Enforcement ...|                null|  DSD/Code Enforcement|                YES|\n",
      "|   Dangerous Premise|Code Enforcement ...|  DSD/Code Enforcement|                YES|\n",
      "|Dangerous Premise...|Code Enforcement ...|  DSD/Code Enforcement|                YES|\n",
      "|Director's Office...|Trans & Cap Impro...|  Trans & Cap Impro...|                YES|\n",
      "|          District 1|        City Council|          City Council|                 NO|\n",
      "|         District 10|        City Council|          City Council|                 NO|\n",
      "|          District 2|        City Council|          City Council|                 NO|\n",
      "|          District 3|        City Council|          City Council|                 NO|\n",
      "|          District 6|        City Council|          City Council|                 NO|\n",
      "|          District 7|        City Council|          City Council|                 NO|\n",
      "|          District 8|        City Council|          City Council|                 NO|\n",
      "|          District 9|        City Council|          City Council|                 NO|\n",
      "|Engineering Division|Development Services|  DSD/Code Enforcement|                YES|\n",
      "|    Facility License|        Metro Health|          Metro Health|                YES|\n",
      "+--------------------+--------------------+----------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "--- source ---\n",
      "+---------+--------------------+\n",
      "|source_id|     source_username|\n",
      "+---------+--------------------+\n",
      "|   100137|    Merlene Blodgett|\n",
      "|   103582|         Carmen Cura|\n",
      "|   106463|     Richard Sanchez|\n",
      "|   119403|      Betty De Hoyos|\n",
      "|   119555|      Socorro Quiara|\n",
      "|   119868| Michelle San Miguel|\n",
      "|   120752|      Eva T. Kleiber|\n",
      "|   124405|           Lori Lara|\n",
      "|   132408|       Leonard Silva|\n",
      "|   135723|        Amy Cardenas|\n",
      "|   136202|    Michelle Urrutia|\n",
      "|   136979|      Leticia Garcia|\n",
      "|   137943|    Pamela K. Baccus|\n",
      "|   138605|        Marisa Ozuna|\n",
      "|   138650|      Kimberly Green|\n",
      "|   138650|Kimberly Green-Woods|\n",
      "|   138793| Guadalupe Rodriguez|\n",
      "|   138810|       Tawona Martin|\n",
      "|   139342|     Jessica Mendoza|\n",
      "|   139344|        Isis Mendoza|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"--- case ---\")\n",
    "case_df.show(1, vertical=True)\n",
    "print(\"--- dept ---\")\n",
    "dept_df.show()\n",
    "print(\"--- source ---\")\n",
    "source_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's see how writing to the local disk works in spark:\n",
    "\n",
    "    - Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to json\n",
    "source_df.write.json(\"source_json\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to csv\n",
    "source_df.write.csv(\"source_csv\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Inspect your folder structure. What do you notice?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - There are folders for each json and csv. Within each file folder is a success document showing that the write was a success and a document with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect the data in your dataframes. Are the data types appropriate? Write the code necessary to cast the values to the appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[source_id: string, source_username: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dtypes for source_df\n",
    "source_df\n",
    "\n",
    "#takeaways: source_id is a string and can stay that way for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[dept_division: string, dept_name: string, standardized_dept_name: string, dept_subject_to_SLA: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dtypes for dept\n",
    "dept_df\n",
    "\n",
    "#takeaways:\n",
    "# All good except for dept_subject_to_SLA could be converted to abool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[case_id: int, case_opened_date: string, case_closed_date: string, SLA_due_date: string, case_late: string, num_days_late: double, case_closed: string, dept_division: string, service_request_type: string, SLA_days: double, case_status: string, source_id: string, request_address: string, council_district: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dtypes for case_df\n",
    "case_df\n",
    "\n",
    "#takeaways:\n",
    "#case_id --> string\n",
    "#case_opened_date, case_closed_date, SLA_due_date --> datetime\n",
    "#case_late --> abool\n",
    "#SLA_days --> int\n",
    "#council_district --> string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------\n",
      " case_id              | 1014127332           \n",
      " case_opened_date     | 1/1/18 0:42          \n",
      " case_closed_date     | 1/1/18 12:29         \n",
      " SLA_due_date         | 9/26/20 0:42         \n",
      " case_late            | NO                   \n",
      " num_days_late        | -998.5087616000001   \n",
      " case_closed          | YES                  \n",
      " dept_division        | Field Operations     \n",
      " service_request_type | Stray Animal         \n",
      " SLA_days             | 999.0                \n",
      " case_status          | Closed               \n",
      " source_id            | svcCRMLS             \n",
      " request_address      | 2315  EL PASO ST,... \n",
      " council_district     | 5                    \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case_id --> string\n",
    "case_df.select(case_df.case_id.cast(\"string\"))\n",
    "\n",
    "#case_opened_date, case_closed_date, SLA_due_date --> datetime\n",
    "\n",
    "fmt = \"M/d/yy H:mm\"\n",
    "case_df = (\n",
    "    case_df.withColumn(\"case_opened_date\", to_timestamp(\"case_opened_date\", fmt))\n",
    "    .withColumn(\"case_closed_date\", to_timestamp(\"case_opened_date\", fmt))\n",
    "    .withColumn(\"case_due_date\", to_timestamp(\"case_opened_date\", fmt))\n",
    ")\n",
    "\n",
    "#case_late --> abool\n",
    "\n",
    "\n",
    "#SLA_days --> int\n",
    "#council_district --> string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|min(num_days_late)|\n",
      "+------------------+\n",
      "|       0.060810185|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How old is the latest currently open issue?\n",
    "case_df.where((case_df.case_closed == 'NO') & (case_df.num_days_late > 0)).select(min(case_df.num_days_late)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(num_days_late)|\n",
      "+------------------+\n",
      "|       348.6458333|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How long has the oldest (in terms of days since opened) currently opened issue been open?\n",
    "case_df.where((case_df.case_closed == 'NO') & (case_df.num_days_late > 0)).select(max(case_df.num_days_late)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How many Stray Animal cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|service_request_type|count|\n",
      "+--------------------+-----+\n",
      "|        Stray Animal|26760|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Need to groupby case type\n",
    "(\n",
    "    case_df.groupBy('service_request_type').count()\n",
    "    .where(case_df.service_request_type == 'Stray Animal').show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113902"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    case_df.select('service_request_type')\n",
    "    .where(case_df.dept_division == 'Field Operations')\n",
    "    .where(case_df.service_request_type != 'Officer Standby').count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convert the council_district column to a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df = case_df.withColumn(\"council_district\", col(\"council_district\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- case_opened_date: timestamp (nullable = true)\n",
      " |-- case_closed_date: timestamp (nullable = true)\n",
      " |-- SLA_due_date: string (nullable = true)\n",
      " |-- case_late: string (nullable = true)\n",
      " |-- num_days_late: double (nullable = true)\n",
      " |-- case_closed: string (nullable = true)\n",
      " |-- dept_division: string (nullable = true)\n",
      " |-- service_request_type: string (nullable = true)\n",
      " |-- SLA_days: double (nullable = true)\n",
      " |-- case_status: string (nullable = true)\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- request_address: string (nullable = true)\n",
      " |-- council_district: string (nullable = true)\n",
      " |-- case_due_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract the year from the case_closed_date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df = case_df.withColumn('year', year(\"case_closed_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2018|\n",
      "+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_df.select(case_df.year).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Convert num_days_late from days to hours in new columns num_hours_late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+-------------------+----+--------------------+\n",
      "|   case_id|   case_opened_date|   case_closed_date|SLA_due_date|case_late|      num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|      case_due_date|year|      num_hours_late|\n",
      "+----------+-------------------+-------------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+-------------------+----+--------------------+\n",
      "|1014127332|2018-01-01 00:42:00|2018-01-01 00:42:00|9/26/20 0:42|       NO| -998.5087616000001|        YES|Field Operations|        Stray Animal|      999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|2018-01-01 00:42:00|2018|  -41.60453173333334|\n",
      "|1014127333|2018-01-01 00:46:00|2018-01-01 00:46:00| 1/5/18 8:30|       NO|-2.0126041669999997|        YES|     Storm Water|Removal Of Obstru...|4.322222222|     Closed| svcCRMSS|2215  GOLIAD RD, ...|               3|2018-01-01 00:46:00|2018|-0.08385850695833331|\n",
      "|1014127334|2018-01-01 00:48:00|2018-01-01 00:48:00| 1/5/18 8:30|       NO|       -3.022337963|        YES|     Storm Water|Removal Of Obstru...|4.320729167|     Closed| svcCRMSS|102  PALFREY ST W...|               3|2018-01-01 00:48:00|2018|-0.12593074845833332|\n",
      "|1014127335|2018-01-01 01:29:00|2018-01-01 01:29:00|1/17/18 8:30|       NO|       -15.01148148|        YES|Code Enforcement|Front Or Side Yar...|16.29188657|     Closed| svcCRMSS|114  LA GARDE ST,...|               3|2018-01-01 01:29:00|2018|        -0.625478395|\n",
      "|1014127336|2018-01-01 01:34:00|2018-01-01 01:34:00| 1/1/18 4:34|      YES|0.37216435200000003|        YES|Field Operations|Animal Cruelty(Cr...|      0.125|     Closed| svcCRMSS|734  CLEARVIEW DR...|               7|2018-01-01 01:34:00|2018|0.015506848000000002|\n",
      "+----------+-------------------+-------------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+-------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_df.withColumn('num_hours_late', case_df.num_days_late / 24).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Join the case data with the source and department data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+----------+-------------------+-------------------+------------+---------+-------------------+-----------+--------------------+-----------+-----------+--------------------+----------------+-------------------+----+---------------+--------------------+----------------------+-------------------+\n",
      "|   dept_division|source_id|   case_id|   case_opened_date|   case_closed_date|SLA_due_date|case_late|      num_days_late|case_closed|service_request_type|   SLA_days|case_status|     request_address|council_district|      case_due_date|year|source_username|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+----------------+---------+----------+-------------------+-------------------+------------+---------+-------------------+-----------+--------------------+-----------+-----------+--------------------+----------------+-------------------+----+---------------+--------------------+----------------------+-------------------+\n",
      "|Field Operations| svcCRMLS|1014127332|2018-01-01 00:42:00|2018-01-01 00:42:00|9/26/20 0:42|       NO| -998.5087616000001|        YES|        Stray Animal|      999.0|     Closed|2315  EL PASO ST,...|               5|2018-01-01 00:42:00|2018|       svcCRMLS|Animal Care Services|  Animal Care Services|                YES|\n",
      "|     Storm Water| svcCRMSS|1014127333|2018-01-01 00:46:00|2018-01-01 00:46:00| 1/5/18 8:30|       NO|-2.0126041669999997|        YES|Removal Of Obstru...|4.322222222|     Closed|2215  GOLIAD RD, ...|               3|2018-01-01 00:46:00|2018|       svcCRMSS|Trans & Cap Impro...|  Trans & Cap Impro...|                YES|\n",
      "+----------------+---------+----------+-------------------+-------------------+------------+---------+-------------------+-----------+--------------------+-----------+-----------+--------------------+----------------+-------------------+----+---------------+--------------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#first I'll join the case and source dataframes\n",
    "case_source = case_df.join(source_df, on='source_id', how='left')\n",
    "\n",
    "#Then join the dept df to the case_source df\n",
    "case_source_dept = case_source.join(dept_df, on='dept_division', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------\n",
      " dept_division          | Field Operations     \n",
      " source_id              | svcCRMLS             \n",
      " case_id                | 1014127332           \n",
      " case_opened_date       | 2018-01-01 00:42:00  \n",
      " case_closed_date       | 2018-01-01 00:42:00  \n",
      " SLA_due_date           | 9/26/20 0:42         \n",
      " case_late              | NO                   \n",
      " num_days_late          | -998.5087616000001   \n",
      " case_closed            | YES                  \n",
      " service_request_type   | Stray Animal         \n",
      " SLA_days               | 999.0                \n",
      " case_status            | Closed               \n",
      " request_address        | 2315  EL PASO ST,... \n",
      " council_district       | 5                    \n",
      " case_due_date          | 2018-01-01 00:42:00  \n",
      " year                   | 2018                 \n",
      " source_username        | svcCRMLS             \n",
      " dept_name              | Animal Care Services \n",
      " standardized_dept_name | Animal Care Services \n",
      " dept_subject_to_SLA    | YES                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the join\n",
    "case_source_dept.show(1,  vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Are there any cases that do not have a request source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column source_username#1255 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-877ebe3316d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcase_source_dept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_source_dept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_username\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_source_dept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_username\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/group.py\u001b[0m in \u001b[0;36m_api\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column source_username#1255 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
     ]
    }
   ],
   "source": [
    "case_source_dept.rollup(case_source_dept.source_username).count().sort(case_source_dept.source_username).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. What are the top 10 service request types in terms of number of requests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----+\n",
      "|service_request_type      |count|\n",
      "+--------------------------+-----+\n",
      "|No Pickup                 |89210|\n",
      "|Overgrown Yard/Trash      |66403|\n",
      "|Bandit Signs              |32968|\n",
      "|Damaged Cart              |31163|\n",
      "|Front Or Side Yard Parking|28920|\n",
      "+--------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    case_source_dept.select('service_request_type')\n",
    "    .groupBy('service_request_type').count()\n",
    "    .sort(desc('count')).show(5,truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What are the top 10 service request types in terms of average days late?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------+\n",
      "|service_request_type                  |avg_days_late|\n",
      "+--------------------------------------+-------------+\n",
      "|Zoning: Junk Yards                    |175.96       |\n",
      "|Labeling for Used Mattress            |162.43       |\n",
      "|Record Keeping of Used Mattresses     |154.0        |\n",
      "|Signage Requied for Sale of Used Mattr|151.64       |\n",
      "|Storage of Used Mattress              |142.11       |\n",
      "|Zoning: Recycle Yard                  |135.93       |\n",
      "|Donation Container Enforcement        |131.76       |\n",
      "|License Requied Used Mattress Sales   |128.8        |\n",
      "|Traffic Signal Graffiti               |101.8        |\n",
      "|Complaint                             |72.87        |\n",
      "+--------------------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    case_source_dept.groupBy('service_request_type')\n",
    "    .agg(round(mean(case_source_dept.num_days_late),2).alias('avg_days_late'))\n",
    "    .sort(desc('avg_days_late')).show(10,truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Does number of days late depend on department?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------+\n",
      "|dept_name                |avg_days_late|\n",
      "+-------------------------+-------------+\n",
      "|null                     |135.93       |\n",
      "|Customer Service         |59.74        |\n",
      "|Development Services     |13.43        |\n",
      "|Solid Waste Management   |-2.2         |\n",
      "|Metro Health             |-4.91        |\n",
      "|Parks and Recreation     |-5.25        |\n",
      "|Trans & Cap Improvements |-20.61       |\n",
      "|Code Enforcement Services|-38.7        |\n",
      "|Animal Care Services     |-226.52      |\n",
      "|City Council             |null         |\n",
      "+-------------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    case_source_dept.groupBy('dept_name').agg(round(mean(case_source_dept.num_days_late),2).alias('avg_days_late'))\n",
    "    .sort(desc('avg_days_late')).show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. How do number of days late depend on department and request type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------------------------+-------------+\n",
      "|dept_name                |service_request_type                  |avg_days_late|\n",
      "+-------------------------+--------------------------------------+-------------+\n",
      "|null                     |Zoning: Recycle Yard                  |135.93       |\n",
      "|Animal Care Services     |Trapped/Confined Animal               |0.25         |\n",
      "|Animal Care Services     |Stray Animal                          |-998.81      |\n",
      "|Animal Care Services     |Spay/Neuter Request Response          |-6.98        |\n",
      "|Animal Care Services     |Public Nuisance(Own Animal)           |-2.2         |\n",
      "|Animal Care Services     |Officer Standby                       |-0.07        |\n",
      "|Animal Care Services     |Injured Animal(Critical)              |-0.07        |\n",
      "|Animal Care Services     |City Council Animal Request           |-1.55        |\n",
      "|Animal Care Services     |Animal Permits Request                |22.2         |\n",
      "|Animal Care Services     |Animal Neglect                        |7.33         |\n",
      "|Animal Care Services     |Animal Cruelty(Critical)              |-0.06        |\n",
      "|Animal Care Services     |Animal Bite(Non-Critical)             |-2.51        |\n",
      "|Animal Care Services     |Animal Bite(Critical)                 |0.02         |\n",
      "|Animal Care Services     |Aggressive Animal(Non-Critical)       |2.65         |\n",
      "|Animal Care Services     |Aggressive Animal(Critical)           |16.7         |\n",
      "|City Council             |Request for Research/Information      |null         |\n",
      "|City Council             |CCO_Request for Research/Information_1|null         |\n",
      "|Code Enforcement Services|Zoning: Visual Obstruction            |-54.32       |\n",
      "|Code Enforcement Services|Zoning: Setbacks                      |-85.32       |\n",
      "|Code Enforcement Services|Zoning: Oversized Vehicles            |-4.67        |\n",
      "+-------------------------+--------------------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    case_source_dept.groupBy('dept_name','service_request_type').agg(round(mean(case_source_dept.num_days_late),2).alias('avg_days_late'))\n",
    "    .sort(asc('dept_name'),desc('service_request_type'),desc('avg_days_late')).show(truncate=False)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
